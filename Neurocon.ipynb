{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6253d18-a381-4c91-a344-567d0c110d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos control encontrados: 16\n",
      "Archivos parkinson encontrados: 27\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "def buscar_archivos_nii_gz(directorio, cadena):\n",
    "    archivos_con_cadena = []\n",
    "\n",
    "    # Recorrer todos los directorios y archivos en el directorio dado\n",
    "    for raiz, carpetas, archivos in os.walk(directorio):\n",
    "        for archivo in fnmatch.filter(archivos, '*' + cadena + '*'):\n",
    "            ruta_completa = os.path.join(raiz, archivo)\n",
    "            archivos_con_cadena.append(ruta_completa)\n",
    "\n",
    "    return archivos_con_cadena\n",
    "\n",
    "# Ejemplo de uso\n",
    "directorio_a_buscar_control = 'duenhas/Preprocessed/control'\n",
    "directorio_a_buscar_parkinson = 'duenhas/Preprocessed/parkinson'\n",
    "cadena_a_buscar = 'brain_mask_applied.nii.gz'\n",
    "control = buscar_archivos_nii_gz(directorio_a_buscar_control, cadena_a_buscar)\n",
    "parkison = buscar_archivos_nii_gz(directorio_a_buscar_parkinson, cadena_a_buscar)\n",
    "\n",
    "\n",
    "# Imprimir la lista de archivos encontrados\n",
    "print(\"Archivos control encontrados:\", len(control))\n",
    "print(\"Archivos parkinson encontrados:\", len(parkison))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d50a922-fb6b-4681-bd0c-8a2ed9fbca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import nifti_labels_masker\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from nilearn import plotting as nlp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "138ea1fa-bb2c-4b04-af34-92fb5b7be5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Listas de rutas para los grupos \"parkinson\" y \"control\"\n",
    "\n",
    "\n",
    "# Función para cargar las imágenes\n",
    "def cargar_imagenes(lista_rutas):\n",
    "    imagenes = []\n",
    "    for ruta in lista_rutas:\n",
    "        img = nib.load(ruta)\n",
    "        datos = img.get_fdata()\n",
    "        imagenes.append(datos)\n",
    "    return imagenes\n",
    "\n",
    "# Cargar las imágenes para el grupo \"parkinson\"\n",
    "imagenes_parkinson = cargar_imagenes(parkison)\n",
    "etiquetas_parkinson = np.ones(len(imagenes_parkinson))  # Etiqueta 1 para \"parkinson\"\n",
    "\n",
    "# Cargar las imágenes para el grupo \"control\"\n",
    "imagenes_control = cargar_imagenes(control)\n",
    "etiquetas_control = np.zeros(len(imagenes_control))  # Etiqueta 0 para \"control\"\n",
    "\n",
    "# Combina los datos y etiquetas de ambos grupos\n",
    "conjunto_datos = np.concatenate([imagenes_parkinson, imagenes_control])\n",
    "etiquetas = np.concatenate([etiquetas_parkinson, etiquetas_control])\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "conjunto_entrenamiento, conjunto_prueba, etiquetas_entrenamiento, etiquetas_prueba = train_test_split(\n",
    "    conjunto_datos, etiquetas, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Ahora puedes utilizar conjunto_entrenamiento y etiquetas_entrenamiento para entrenar tu CNN\n",
    "# y conjunto_prueba y etiquetas_prueba para evaluar su rendimiento.\n",
    "\n",
    "# Asegúrate de adaptar las rutas y etiquetas según tu estructura de datos específica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "632ebcf5-f79c-42ca-b682-bf8d34959875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 21:03:28.700454: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-10 21:03:29.692943: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-10 21:03:29.692974: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-10 21:03:29.701704: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-10 21:03:30.320908: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-10 21:03:30.328741: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 21:03:32.593866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-10 21:03:34.731640: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal\n",
      "2023-11-10 21:03:34.731667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: 52ecac76f25a\n",
      "2023-11-10 21:03:34.731671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: 52ecac76f25a\n",
      "2023-11-10 21:03:34.731811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.113.1\n",
      "2023-11-10 21:03:34.731823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.113.1\n",
      "2023-11-10 21:03:34.731826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.113.1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tamaño_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m modelo \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Capa de convolución 3D\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m modelo\u001b[38;5;241m.\u001b[39madd(Conv3D(\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[43mtamaño_x\u001b[49m, tamaño_y, tamaño_z, canales)))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Puedes agregar más capas de convolución y max pooling según sea necesario\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Capa de max pooling 3D\u001b[39;00m\n\u001b[1;32m     12\u001b[0m modelo\u001b[38;5;241m.\u001b[39madd(MaxPooling3D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tamaño_x' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "\n",
    "# Definir el modelo de la CNN\n",
    "modelo = Sequential()\n",
    "\n",
    "# Capa de convolución 3D\n",
    "modelo.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(tamaño_x, tamaño_y, tamaño_z, canales)))\n",
    "# Puedes agregar más capas de convolución y max pooling según sea necesario\n",
    "\n",
    "# Capa de max pooling 3D\n",
    "modelo.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Aplanar los datos para la capa completamente conectada\n",
    "modelo.add(Flatten())\n",
    "\n",
    "# Capas densas (completamente conectadas)\n",
    "modelo.add(Dense(128, activation='relu'))\n",
    "modelo.add(Dropout(0.5))  # Agregar dropout para reducir el sobreajuste\n",
    "modelo.add(Dense(1, activation='sigmoid'))  # Salida binaria, puedes ajustar según tu tarea\n",
    "\n",
    "# Compilar el modelo\n",
    "modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "modelo.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
